# pages/4_Coach_IA.py
import streamlit as st
import os
import sys
from datetime import datetime

# Configurar certificado SSL ANTES de importar genai (para VPN corporativa)
proxy_cert = os.path.expanduser("~/Credentials/rootcaCert.pem")
combined_cert_path = None

if os.path.exists(proxy_cert):
    # Intentar combinar el certificado proxy con los certificados del sistema
    system_certs = None

    # Buscar certificados del sistema en macOS
    possible_system_certs = [
        '/etc/ssl/cert.pem',
        '/usr/local/etc/openssl/cert.pem',
        '/System/Library/OpenSSL/cert.pem'
    ]

    for cert_path in possible_system_certs:
        if os.path.exists(cert_path):
            system_certs = cert_path
            break

    # Crear certificado combinado temporal
    if system_certs:
        try:
            combined_cert_path = os.path.expanduser("~/.config/combined_cert.pem")
            os.makedirs(os.path.dirname(combined_cert_path), exist_ok=True)

            # Leer y combinar certificados
            with open(combined_cert_path, 'w') as outfile:
                # Primero el proxy cert
                with open(proxy_cert, 'r') as infile:
                    outfile.write(infile.read())
                    outfile.write('\n')
                # Luego los certificados del sistema
                with open(system_certs, 'r') as infile:
                    outfile.write(infile.read())

            # Usar el certificado combinado
            os.environ['GRPC_DEFAULT_SSL_ROOTS_FILE_PATH'] = combined_cert_path
            os.environ['SSL_CERT_FILE'] = combined_cert_path
            os.environ['REQUESTS_CA_BUNDLE'] = combined_cert_path
            os.environ['CURL_CA_BUNDLE'] = combined_cert_path
        except Exception as e:
            # Si falla, usar solo el proxy cert
            print(f"No se pudo crear certificado combinado: {e}")
            os.environ['GRPC_DEFAULT_SSL_ROOTS_FILE_PATH'] = proxy_cert
            os.environ['SSL_CERT_FILE'] = proxy_cert
            os.environ['REQUESTS_CA_BUNDLE'] = proxy_cert
    else:
        # Si no hay certificados del sistema, usar solo el proxy
        os.environ['GRPC_DEFAULT_SSL_ROOTS_FILE_PATH'] = proxy_cert
        os.environ['SSL_CERT_FILE'] = proxy_cert
        os.environ['REQUESTS_CA_BUNDLE'] = proxy_cert

    # Para gRPC espec√≠ficamente
    os.environ['GRPC_TRACE'] = ''  # Deshabilitar logging verbose de gRPC
    os.environ['GRPC_VERBOSITY'] = 'ERROR'  # Solo mostrar errores

import google.generativeai as genai

# A√±adir el directorio src al path para importar m√≥dulos
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from utils import ai_functions
from utils import ai_context
from utils import gemini_tools
from utils.db_config import get_connection

st.set_page_config(layout="wide")
st.title("ü§ñ Coach con Inteligencia Artificial")
st.markdown("Tu entrenador personal basado en datos y IA. Analiza tu progreso y dise√±a tu plan de entrenamiento.")

# Inicializar session state
if "messages" not in st.session_state:
    st.session_state.messages = []
    # Cargar contexto inicial autom√°ticamente
    initial_context = ai_context.generate_initial_context()
    if initial_context:
        greeting = ai_context.get_contextual_greeting()
        welcome_message = f"{greeting}\n\n**Contexto actual:**\n{initial_context}\n\n¬øEn qu√© puedo ayudarte hoy?"
        st.session_state.messages.append({"role": "assistant", "content": welcome_message})

if "gemini_configured" not in st.session_state:
    # Verificar API key (primero en st.secrets, luego en variables de entorno)
    try:
        gemini_api_key = st.secrets.get("GEMINI_API_KEY")
    except:
        gemini_api_key = os.getenv("GEMINI_API_KEY")

    if not gemini_api_key:
        st.error("‚ö†Ô∏è No se encontr√≥ la API key de Gemini. Por favor, a√±ade GEMINI_API_KEY a tu archivo .env o secrets")
        st.info("La API key debe empezar con 'AIza...'")
        st.stop()

    # Mostrar info de la API key (solo primeros y √∫ltimos caracteres para seguridad)
    if len(gemini_api_key) > 10:
        masked_key = f"{gemini_api_key[:6]}...{gemini_api_key[-4:]}"
        st.sidebar.caption(f"üîë API Key: {masked_key}")

    # Configurar Gemini
    try:
        genai.configure(api_key=gemini_api_key)
        st.session_state.gemini_configured = True
        st.sidebar.success("‚úÖ Gemini configurado")
    except Exception as e:
        st.error(f"Error al configurar Gemini: {str(e)}")
        st.stop()

# System prompt con contexto del entrenador
from datetime import datetime
CURRENT_DATE = datetime.now().strftime('%Y-%m-%d')
CURRENT_YEAR = datetime.now().year

SYSTEM_PROMPT = f"""Eres un entrenador personal anal√≠tico y data-driven especializado en running.

**IMPORTANTE - Fecha actual: {CURRENT_DATE} (a√±o {CURRENT_YEAR})**
- Cuando planifiques entrenamientos, SIEMPRE usa el a√±o {CURRENT_YEAR} en las fechas
- Verifica que las fechas est√©n en el futuro respecto a {CURRENT_DATE}

## üéØ Tu Misi√≥n
Ayudar al atleta a mejorar su rendimiento priorizando:
1. **Salud y consistencia** (Prioridad #1)
2. **Rendimiento** (Prioridad #2)

## üìã Mandamientos del Coach

### 1. Data-First Siempre
- **ANTES de responder**, consulta `get_runner_profile()` para conocer al atleta
- Analiza datos recientes con `get_recent_activities()` y `analyze_performance_trends()`
- Basa tus recomendaciones en datos reales, NO en plantillas gen√©ricas

### 2. Razonamiento Fisiol√≥gico (El "Por Qu√©")
NUNCA propongas un entreno sin explicar su prop√≥sito fisiol√≥gico:
- **Series VO2max**: Mejoran capacidad cardiovascular y econom√≠a de carrera
- **Tempo/Umbral**: Elevan el umbral l√°ctico y resistencia a ritmo r√°pido
- **Tirada larga**: Adaptaciones musculares, consumo de grasa, resistencia aer√≥bica
- **Rodaje suave**: Recuperaci√≥n activa, construcci√≥n de base aer√≥bica sin fatiga

### 3. Estructura Clara y Detallada (Formato de Respuesta)
Organiza SIEMPRE tus respuestas con estas secciones:

**### Filosof√≠a/Contexto**
(Explica el "por qu√©" general del plan, el enfoque que sigues)

**### An√°lisis de Estado Actual**
S√© MUY ESPEC√çFICO con n√∫meros reales:
- Ejemplos de buen an√°lisis:
  ‚úÖ "Tu FC media en rodajes baj√≥ de 165 a 159 ppm (-3.6%) manteniendo ritmo 5:30/km ‚Üí mejora aer√≥bica clara"
  ‚úÖ "Has pasado de 4x1000 @ 4:25 (FC 178) a 4x1000 @ 4:20 (FC 175) ‚Üí +3% econom√≠a"
  ‚ùå "Hay indicios de mejora aer√≥bica" (demasiado vago)
- Si usas `analyze_performance_trends()`, cita los n√∫meros espec√≠ficos que devuelve
- Si usas `analyze_training_load_advanced()`, explica CADA warning detectado

**### Plan Propuesto - Semana por Semana**
**MUY IMPORTANTE**: NUNCA ejecutes `create_training_plan()` o `add_workout_to_current_plan()` sin aprobaci√≥n.
Primero presenta el plan COMPLETO en formato texto:

Ejemplo de formato DETALLADO correcto:
```
**Semana 1 (17-23/11): Afinar y Tocar Ritmo**

üìÖ Martes 18/11 - Sesi√≥n de calidad (10km total)
- Calentamiento: 2km @ 5:45/km + movilidad din√°mica
- Bloque principal: 4x1200m @ 4:20-4:25 (rec: 90s trote suave)
- Acabado (chispa): 4x200m @ 3:35-3:40 (rec: 1min parado)
- Enfriamiento: 1.5km suaves
üî¨ Por qu√©: Los 1200m a ritmo 10k real activan tu gluc√≥lisis y VO2max sin fatiga extrema. Los 200m finales despiertan velocidad neuromuscular.

üìÖ Jueves 20/11 - Rodaje regenerativo (8km)
- Ritmo: 5:45-6:00/km (conversacional)
- FC objetivo: <150ppm (Zona 1-2)
üî¨ Por qu√©: Recuperaci√≥n activa. Limpiar lactato, mantener capilares activos sin fatiga.

üìÖ Domingo 23/11 - Tirada con progresi√≥n (12km)
- Estructura: 9km @ 5:30/km + 3km progresivos (5:00 ‚Üí 4:40 ‚Üí 4:30)
- FC: Dejar que suba naturalmente en la progresi√≥n
üî¨ Por qu√©: Mantener resistencia aer√≥bica. Los 3km finales son "recordatorio" del ritmo de carrera.
```

**### Estrategia de Ejecuci√≥n**
(Consejos t√°cticos para carreras o entrenamientos clave)

**### Pregunta de Aprobaci√≥n**
"¬øTe parece bien este plan? Si est√°s de acuerdo, confirma y lo crear√© en tu calendario. Si quieres ajustar algo (d√≠as, distancias, ritmos), dime qu√© cambiar."

### 4. Detective de Fatiga
Antes de proponer planes exigentes:
- Usa `analyze_training_load_advanced()` para detectar sobreentrenamiento
- Examina tendencias FC/ritmo con `analyze_performance_trends()`
- Si detectas fatiga, reduce volumen o prop√≥n semana de descarga

### 5. Predicciones Realistas
- Usa `predict_race_times()` para estimar tiempos basados en marcas reales
- S√© honesto sobre la viabilidad de objetivos
- Ajusta expectativas seg√∫n el entrenamiento espec√≠fico disponible

## üèÉ Planificaci√≥n de Entrenamientos

**Estructura t√≠pica (3 d√≠as/semana):**
- **D√≠a 1**: Calidad (series/tempo) - "La chispa"
- **D√≠a 2**: Tirada larga - "El pilar de resistencia"
- **D√≠a 3**: Rodaje suave (Z1-Z2) - "Recuperaci√≥n activa"

**‚ö†Ô∏è FLUJO DE APROBACI√ìN OBLIGATORIO:**

1Ô∏è‚É£ **Primera respuesta** ‚Üí Presenta el plan COMPLETO en texto con todos los detalles
2Ô∏è‚É£ Termina preguntando: "¬øTe parece bien? ¬øLo creo en tu calendario?"
3Ô∏è‚É£ **ESPERA la confirmaci√≥n del usuario**
4Ô∏è‚É£ Solo DESPU√âS de confirmaci√≥n ‚Üí Ejecuta `create_training_plan()` o `add_workout_to_current_plan()`

**‚ùå NUNCA hagas esto:**
- Ejecutar `create_training_plan()` en la primera respuesta sin preguntar
- Crear entrenamientos sin mostrar primero todo el plan detallado
- Asumir que el usuario quiere el plan sin confirmarlo expl√≠citamente

**‚úÖ SIEMPRE haz esto:**
- Mostrar plan completo en texto primero
- Preguntar expl√≠citamente si est√° de acuerdo
- Esperar mensaje de confirmaci√≥n tipo "s√≠", "adelante", "cr√©alo", "ok"
- ENTONCES ejecutar las funciones de creaci√≥n

**Funciones para planificar (solo DESPU√âS de aprobaci√≥n):**
- `create_training_plan()`: Crear plan completo NUEVO (desactiva plan anterior)
- `add_workout_to_current_plan()`: A√±adir entrenos al plan activo
- `update_workout()`: Modificar entreno espec√≠fico
- `delete_workout()`: Eliminar entreno del plan

**Requisitos t√©cnicos:**
- `week_start_date` debe ser un LUNES (formato YYYY-MM-DD)
- Tipos de workout: "calidad", "tirada_larga", "rodaje", "recuperacion", "tempo", "series"
- Incluye descripciones detalladas con estructura, repeticiones, ritmos
- Especifica ritmos objetivos claros (ej: "4:20-4:25" o "5:00 (r√°pido) / 5:30 (recuperaci√≥n)")

## üîç Uso de Datos

**IDs de actividades:**
- Son strings de 16 d√≠gitos (ej: "16435421117")
- Si el contexto inicial incluye IDs entre par√©ntesis, √∫salos EXACTAMENTE
- Si necesitas un ID, primero llama a `get_recent_activities()`
- NUNCA inventes IDs

**An√°lisis proactivo:**
- Lee notas privadas de Strava (campo `private_note` en activities) - el atleta pone ah√≠ su feedback
- Compara m√©tricas entre entrenamientos similares
- Busca patrones de mejora o fatiga

## üí° Principios No Negociables

1. **Ante dolor agudo o molestia**: PARA. Sustituye por descanso o cross-training
2. **Progresi√≥n de carga**: M√°ximo 10-15% aumento semanal de volumen
3. **Recuperaci√≥n**: El sue√±o es tan importante como el entrenamiento
4. **Flexibilidad**: Plan B siempre disponible si hay fatiga extrema

Usa tus funciones de an√°lisis proactivamente para dar recomendaciones basadas en datos reales, no en teor√≠a gen√©rica."""


def save_chat_to_db(role: str, content: str):
    """Guarda un mensaje en el historial de chat en la BD."""
    conn = get_connection()
    cur = conn.cursor()
    cur.execute("""
        INSERT INTO chat_history (role, content, timestamp)
        VALUES (?, ?, ?)
    """, (role, content, datetime.now().isoformat()))
    conn.commit()
    conn.close()


def load_chat_history(limit: int = 50):
    """Carga el historial de chat desde la BD."""
    conn = get_connection()
    cur = conn.cursor()
    cur.execute("""
        SELECT role, content, timestamp
        FROM chat_history
        ORDER BY timestamp DESC
        LIMIT ?
    """, (limit,))
    rows = cur.fetchall()
    conn.close()

    # Invertir para tener orden cronol√≥gico
    return [{"role": row[0], "content": row[1], "timestamp": row[2]} for row in reversed(rows)]


def get_context_summary():
    """Genera un resumen del contexto actual para el chatbot."""
    try:
        # √öltimas actividades
        recent = ai_functions.get_recent_activities(days=7)
        recent_summary = f"√öltimos 7 d√≠as: {recent['count']} entrenos, {recent['total_km']} km totales."

        # Plan actual
        plan = ai_functions.get_current_plan()
        if plan['plan']:
            plan_summary = f"Plan activo para semana {plan['plan']['week_start_date']} con {plan['num_workouts']} entrenamientos."
        else:
            plan_summary = "No hay plan activo."

        return f"{recent_summary} {plan_summary}"
    except Exception as e:
        return f"No se pudo cargar contexto: {str(e)}"


# Sidebar con opciones
with st.sidebar:
    st.markdown("### ‚öôÔ∏è Opciones")

    # Informaci√≥n del modelo
    st.caption("ü§ñ Modelo: **gemini-2.0-flash-exp**")
    st.caption("   (M√°s estable para function calling)")

    st.divider()

    # Mostrar opciones SSL solo en entorno local (cuando existe certificado proxy)
    proxy_cert = os.path.expanduser("~/Credentials/rootcaCert.pem")
    if os.path.exists(proxy_cert):
        with st.expander("üîß Configuraci√≥n SSL (Solo desarrollo local)"):
            combined_cert = os.path.expanduser("~/.config/combined_cert.pem")

            if os.path.exists(combined_cert):
                st.caption("üîí Usando certificado combinado (proxy + sistema)")
            elif os.path.exists(proxy_cert):
                st.caption("üîí Usando solo certificado proxy")

            # Opci√≥n para desactivar verificaci√≥n SSL (solo para desarrollo)
            if "disable_ssl_verify" not in st.session_state:
                st.session_state.disable_ssl_verify = False

            st.session_state.disable_ssl_verify = st.checkbox(
                "Desactivar verificaci√≥n SSL (solo VPN)",
                value=st.session_state.disable_ssl_verify,
                help="Activa esto si tienes problemas de SSL con la VPN corporativa. Solo para desarrollo."
            )

            if st.session_state.disable_ssl_verify:
                st.warning("‚ö†Ô∏è Verificaci√≥n SSL desactivada")
                # Configurar para no verificar SSL
                os.environ['GRPC_SSL_CIPHER_SUITES'] = 'HIGH'
                import ssl
                ssl._create_default_https_context = ssl._create_unverified_context

            # Test de conexi√≥n
            if st.button("üîå Test de Conexi√≥n a Gemini"):
                with st.spinner("Probando conexi√≥n..."):
                    try:
                        from concurrent.futures import ThreadPoolExecutor, TimeoutError as FuturesTimeoutError

                        test_model = genai.GenerativeModel('gemini-2.0-flash-exp')

                        def test_connection():
                            return test_model.generate_content("Responde solo: OK")

                        # Ejecutar con timeout de 10 segundos
                        with ThreadPoolExecutor(max_workers=1) as executor:
                            future = executor.submit(test_connection)
                            try:
                                test_response = future.result(timeout=10)
                                st.success("‚úÖ Conexi√≥n exitosa con Gemini!")
                                st.caption(f"Respuesta: {test_response.text[:50]}")
                            except FuturesTimeoutError:
                                st.error("‚ùå Timeout: La VPN est√° bloqueando Gemini")
                                st.warning("No podr√°s usar el Coach IA con la VPN conectada")
                    except Exception as e:
                        st.error(f"‚ùå Error de conexi√≥n: {str(e)}")

            # Diagn√≥stico SSL
            st.caption("**Estado de certificados:**")
            if os.path.exists(proxy_cert):
                st.text(f"‚úì Proxy cert: {proxy_cert}")
            else:
                st.text(f"‚úó Proxy cert no encontrado")

            if os.path.exists(combined_cert):
                st.text(f"‚úì Certificado combinado: {combined_cert}")
                # Mostrar tama√±o para verificar que se cre√≥ bien
                size = os.path.getsize(combined_cert)
                st.text(f"  Tama√±o: {size} bytes")
            else:
                st.text(f"‚úó Certificado combinado no creado")

            st.caption("**Variables de entorno SSL:**")
            ssl_vars = ['GRPC_DEFAULT_SSL_ROOTS_FILE_PATH', 'SSL_CERT_FILE', 'REQUESTS_CA_BUNDLE']
            for var in ssl_vars:
                value = os.environ.get(var, 'No configurada')
                st.text(f"{var}: {value}")

            if st.session_state.disable_ssl_verify:
                st.warning("‚ö†Ô∏è Verificaci√≥n SSL desactivada")

            st.caption("**Soluciones si persiste el error:**")
            st.text("""
1. Activa 'Desactivar verificaci√≥n SSL' arriba
2. Descon√©ctate de la VPN corporativa
3. Verifica que el proxy cert sea v√°lido
4. Reinicia Streamlit despu√©s de cambios
            """)

        st.divider()

    if st.button("üÜï Nueva Conversaci√≥n"):
        st.session_state.messages = []
        st.rerun()

    if st.button("üì• Cargar historial"):
        history = load_chat_history(limit=20)
        st.session_state.messages = [
            {"role": msg["role"], "content": msg["content"]}
            for msg in history
        ]
        st.success(f"Cargados {len(history)} mensajes")
        st.rerun()

    if st.button("üîÑ Recargar contexto"):
        initial_context = ai_context.generate_initial_context()
        greeting = ai_context.get_contextual_greeting()
        welcome_message = f"{greeting}\n\n**Contexto actualizado:**\n{initial_context}\n\n¬øQu√© quieres hacer?"
        st.session_state.messages = [{"role": "assistant", "content": welcome_message}]
        st.success("Contexto recargado")
        st.rerun()

    st.divider()

    # Contexto actual
    st.markdown("### üìä Resumen R√°pido")
    with st.spinner("Cargando..."):
        context = get_context_summary()
        st.caption(context)

    # An√°lisis de carga
    with st.expander("üìà An√°lisis de carga"):
        load_analysis = ai_context.check_training_load_progression()
        if load_analysis.get('status') == 'warning':
            st.warning(load_analysis.get('warning', 'Cuidado con la progresi√≥n'))
        elif load_analysis.get('status') == 'ok':
            st.success(f"Progresi√≥n adecuada: {load_analysis.get('increase_percentage', 0):.1f}%")
        elif load_analysis.get('status') == 'low':
            st.info(load_analysis.get('warning', 'Volumen reducido'))

    st.divider()

    # Informaci√≥n sobre funciones disponibles
    with st.expander("üîß Funciones disponibles (12 funciones)"):
        st.markdown("""
        **‚úÖ Function calling activo**

        El coach puede ejecutar autom√°ticamente estas funciones:

        **Consulta de datos:**
        - `get_runner_profile`: Ver tu perfil completo (objetivos, PRs, filosof√≠a)
        - `get_recent_activities`: Ver tus √∫ltimos entrenamientos
        - `get_weekly_stats`: Estad√≠sticas semanales agregadas
        - `get_activity_details`: Detalles completos de un entreno (incluyendo notas privadas)
        - `get_current_plan`: Consultar tu plan activo

        **An√°lisis avanzado:**
        - `analyze_performance_trends`: Detectar mejoras o fatiga (FC vs ritmo)
        - `predict_race_times`: Calculadora de equivalencias de tiempos (F√≥rmula de Riegel)
        - `analyze_training_load_advanced`: Detectar sobreentrenamiento

        **Acciones:**
        - `create_training_plan`: Crear planes de entrenamiento completos
        - `add_workout_to_current_plan`: A√±adir entrenamientos al plan activo
        - `update_workout`: Modificar entrenamientos planificados
        - `delete_workout`: Eliminar entrenamientos del plan

        El modelo decidir√° autom√°ticamente cu√°ndo usar cada funci√≥n seg√∫n
        tu pregunta. Ver√°s un indicador cada vez que se ejecute una funci√≥n.
        """)

# Inicializar bandera de procesamiento pendiente
if "pending_message" not in st.session_state:
    st.session_state.pending_message = False

# Mostrar historial de chat
for message in st.session_state.messages:
    if message["role"] in ["user", "assistant"]:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# Mapeo de nombres de funciones a las funciones reales
FUNCTION_HANDLERS = {
    "get_recent_activities": ai_functions.get_recent_activities,
    "get_weekly_stats": ai_functions.get_weekly_stats,
    "get_activity_details": ai_functions.get_activity_details,
    "get_current_plan": ai_functions.get_current_plan,
    "create_training_plan": ai_functions.create_training_plan,
    "update_workout": ai_functions.update_workout,
    "add_workout_to_current_plan": ai_functions.add_workout_to_current_plan,
    "delete_workout": ai_functions.delete_workout,
    "get_runner_profile": ai_functions.get_runner_profile,
    "analyze_performance_trends": ai_functions.analyze_performance_trends,
    "predict_race_times": ai_functions.predict_race_times,
    "analyze_training_load_advanced": ai_functions.analyze_training_load_advanced,
}


def execute_function_call(function_name: str, function_args: dict):
    """
    Ejecuta una funci√≥n llamada por el modelo.

    Args:
        function_name: Nombre de la funci√≥n a ejecutar
        function_args: Argumentos de la funci√≥n

    Returns:
        Resultado de la funci√≥n
    """
    if function_name not in FUNCTION_HANDLERS:
        return {"error": f"Funci√≥n desconocida: {function_name}"}

    try:
        function = FUNCTION_HANDLERS[function_name]
        result = function(**function_args)
        return result
    except Exception as e:
        return {"error": f"Error ejecutando {function_name}: {str(e)}"}


# Funci√≥n para procesar mensaje del usuario
def process_user_message(prompt):
    """Procesa un mensaje del usuario y obtiene respuesta del modelo con function calling."""
    # Preparar historial de chat para Gemini
    history = []
    for msg in st.session_state.messages[:-1]:  # Todos menos el √∫ltimo (que es el prompt actual)
        if msg["role"] == "user":
            history.append({"role": "user", "parts": [msg["content"]]})
        elif msg["role"] in ["assistant", "model"]:
            history.append({"role": "model", "parts": [msg["content"]]})

    # Obtener respuesta del modelo
    with st.chat_message("assistant"):
        try:
            # Crear modelo con system instruction y herramientas
            # Aumentar max_output_tokens para an√°lisis completos de entrenamientos
            generation_config = {
                "temperature": 0.7,
                "top_p": 0.95,
                "top_k": 40,
                "max_output_tokens": 4096,
            }

            # Usar gemini-2.0-flash-exp que es m√°s estable para function calling
            # gemini-2.5-flash puede generar MALFORMED_FUNCTION_CALL con estructuras complejas
            model = genai.GenerativeModel(
                model_name='gemini-2.0-flash-exp',
                generation_config=generation_config,
                system_instruction=SYSTEM_PROMPT,
                tools=[gemini_tools.running_coach_tools]
            )

            # Iniciar chat con historial
            chat = model.start_chat(history=history)

            # Loop de function calling
            from concurrent.futures import ThreadPoolExecutor, TimeoutError as FuturesTimeoutError

            max_iterations = 5  # Prevenir loops infinitos
            iteration = 0
            current_prompt = prompt
            functions_executed = []
            last_function_result = None  # Para guardar el √∫ltimo resultado de funci√≥n

            while iteration < max_iterations:
                iteration += 1

                # Actualizar spinner con informaci√≥n de progreso
                if iteration == 1:
                    spinner_text = "Pensando..."
                else:
                    spinner_text = f"Procesando funciones ({len(functions_executed)} ejecutadas)..."

                with st.spinner(spinner_text):
                    def send_message():
                        return chat.send_message(current_prompt)

                    # Ejecutar con timeout de 30 segundos
                    with ThreadPoolExecutor(max_workers=1) as executor:
                        future = executor.submit(send_message)
                        try:
                            response = future.result(timeout=30)
                        except FuturesTimeoutError:
                            st.error("‚è±Ô∏è Timeout: La VPN corporativa est√° bloqueando las peticiones a Gemini.")
                            st.info("üí° Opciones:\n- Prueba desde casa sin VPN\n- Descon√©ctate de la VPN temporalmente")
                            raise TimeoutError("La petici√≥n a Gemini tard√≥ demasiado (probablemente bloqueada por VPN)")

                    # Verificar si el modelo quiere llamar funciones
                    if not response.candidates:
                        st.error("No hay candidatos en la respuesta del modelo")
                        st.json({"response": str(response)})
                        return

                    candidate = response.candidates[0]

                    # Verificar si hay contenido
                    if not candidate.content or not candidate.content.parts:
                        st.warning("‚ö†Ô∏è El modelo no pudo generar una respuesta textual.")

                        # Si ejecutamos funciones, mostrar al menos los datos raw
                        if functions_executed and iteration > 1 and last_function_result:
                            st.info("üîß Pero s√≠ obtuvimos estos datos de las funciones ejecutadas:")

                            # Formatear los datos de forma user-friendly
                            if 'activity' in last_function_result:
                                act = last_function_result['activity']
                                st.subheader(f"üìä {act.get('name', 'Actividad')}")
                                st.write(f"**Fecha:** {act.get('start_date_local', 'N/A')[:10]}")
                                st.write(f"**Distancia:** {act.get('distance_km', 0):.2f} km")
                                st.write(f"**Tiempo:** {act.get('moving_time', 0) // 60} minutos")
                                st.write(f"**Ritmo medio:** {(act.get('moving_time', 0) / 60) / act.get('distance_km', 1):.2f} min/km")
                                if act.get('average_heartrate'):
                                    st.write(f"**FC media:** {act.get('average_heartrate', 0):.1f} bpm")
                                if act.get('description'):
                                    st.write(f"**Descripci√≥n:** {act.get('description')}")
                                if act.get('private_note'):
                                    st.write(f"**Notas:** {act.get('private_note')}")

                                # Mostrar info de laps
                                if 'laps' in last_function_result and last_function_result['laps']:
                                    num_laps = len(last_function_result['laps'])
                                    st.write(f"\n**Laps:** {num_laps} laps registrados")

                                    # Calcular estad√≠sticas de laps
                                    laps = last_function_result['laps']
                                    avg_lap_pace = sum(lap.get('moving_time', 0) / 60 / lap.get('distance_km', 1) for lap in laps if lap.get('distance_km', 0) > 0) / num_laps if num_laps > 0 else 0
                                    fastest_lap = min(laps, key=lambda x: x.get('moving_time', float('inf')) / x.get('distance_km', 1) if x.get('distance_km', 0) > 0 else float('inf'))
                                    slowest_lap = max(laps, key=lambda x: x.get('moving_time', 0) / x.get('distance_km', 1) if x.get('distance_km', 0) > 0 else 0)

                                    st.write(f"  - Ritmo medio de laps: {avg_lap_pace:.2f} min/km")
                                    if fastest_lap.get('distance_km', 0) > 0:
                                        st.write(f"  - Lap m√°s r√°pido: Lap {fastest_lap['lap_index']} - {(fastest_lap['moving_time'] / 60) / fastest_lap['distance_km']:.2f} min/km")
                                    if slowest_lap.get('distance_km', 0) > 0:
                                        st.write(f"  - Lap m√°s lento: Lap {slowest_lap['lap_index']} - {(slowest_lap['moving_time'] / 60) / slowest_lap['distance_km']:.2f} min/km")

                                    with st.expander(f"Ver detalles de los {num_laps} laps"):
                                        for lap in laps[:20]:  # Mostrar primeros 20 en la UI
                                            pace = (lap['moving_time'] / 60) / lap['distance_km'] if lap.get('distance_km', 0) > 0 else 0
                                            st.text(f"Lap {lap['lap_index']}: {lap['distance_km']:.2f}km - {pace:.2f} min/km - {lap['moving_time']//60}:{lap['moving_time']%60:02d}")
                                        if num_laps > 20:
                                            st.caption(f"... y {num_laps - 20} laps m√°s")
                            else:
                                st.json(last_function_result)

                        # Mostrar informaci√≥n de debug
                        with st.expander("üîç Debug info"):
                            st.write("Finish reason:", candidate.finish_reason if hasattr(candidate, 'finish_reason') else "No disponible")
                            st.write("Safety ratings:", candidate.safety_ratings if hasattr(candidate, 'safety_ratings') else "No disponible")
                            st.write("Funciones ejecutadas:", functions_executed)
                            st.info("Posibles causas:\n- Respuesta bloqueada por filtros de seguridad\n- Error interno del modelo\n- Demasiados datos para procesar")

                        return

                    # IMPORTANTE: Procesar TODAS las parts (puede haber m√∫ltiples function calls)
                    parts = candidate.content.parts

                    # Separar function calls y texto
                    function_calls_in_turn = []
                    text_parts = []

                    for part in parts:
                        if hasattr(part, 'function_call') and part.function_call:
                            function_calls_in_turn.append(part)
                        elif hasattr(part, 'text') and part.text:
                            text_parts.append(part)

                    # Si hay function calls, ejecutar TODAS
                    if function_calls_in_turn:
                        from google.generativeai.types import content_types
                        function_response_parts = []

                        for part in function_calls_in_turn:
                            function_call = part.function_call
                            function_name = function_call.name
                            function_args = dict(function_call.args)

                            # Registrar funci√≥n ejecutada
                            functions_executed.append(function_name)

                            # Mostrar indicador de que se est√° ejecutando una funci√≥n
                            with st.status(f"üîß Ejecutando: {function_name}", expanded=False) as status:
                                st.json(function_args)

                                # Ejecutar la funci√≥n
                                function_result = execute_function_call(function_name, function_args)
                                last_function_result = function_result  # Guardar para fallback

                                status.update(label=f"‚úÖ {function_name} completado", state="complete")

                            # A√±adir respuesta para esta funci√≥n
                            function_response_parts.append(content_types.to_part({
                                "function_response": {
                                    "name": function_name,
                                    "response": function_result
                                }
                            }))

                        # Enviar TODAS las respuestas de funci√≥n al modelo
                        current_prompt = function_response_parts
                        continue

                    # Si hay texto, es la respuesta final
                    elif text_parts:
                        # Combinar todas las partes de texto
                        response_text = "".join([part.text for part in text_parts])

                        # Mostrar respuesta
                        st.markdown(response_text)

                        # Mostrar funciones ejecutadas si hubo alguna
                        if functions_executed:
                            with st.expander(f"üîç Datos consultados ({len(functions_executed)} funciones)", expanded=False):
                                for func in functions_executed:
                                    st.caption(f"‚Ä¢ {func}")

                        # Guardar en session state y BD
                        st.session_state.messages.append({"role": "assistant", "content": response_text})
                        save_chat_to_db("assistant", response_text)

                        return  # Salir del loop

                    # Si no hay ni function call ni texto, algo sali√≥ mal
                    else:
                        st.warning("El modelo no gener√≥ ni texto ni function call")
                        with st.expander("üîç Debug - tipo de part"):
                            st.write("Part type:", type(part))
                            st.write("Part attributes:", dir(part))
                            st.json({"part": str(part)})
                        return

            # Si llegamos aqu√≠, excedimos el m√°ximo de iteraciones
            st.warning("Se alcanz√≥ el l√≠mite de iteraciones. El modelo puede estar teniendo problemas.")

        except Exception as e:
            st.error(f"‚ùå Error al comunicarse con Gemini:")
            st.code(f"Tipo: {type(e).__name__}\nMensaje: {str(e)}")

            # Manejo espec√≠fico para MALFORMED_FUNCTION_CALL
            if "MALFORMED_FUNCTION_CALL" in str(e):
                st.warning("‚ö†Ô∏è **El modelo intent√≥ llamar a una funci√≥n pero gener√≥ JSON inv√°lido.**")
                st.info("""
**Soluciones recomendadas:**
1. üîÑ Reformula tu solicitud de forma m√°s simple
2. ‚öôÔ∏è Cambia a `gemini-2.0-flash-exp` (m√°s estable para function calling)
3. üîß Si el problema persiste, reporta este error

**Nota t√©cnica:** `gemini-2.5-flash` es m√°s reciente pero puede ser menos estable con llamadas a funciones complejas.
                """)

                # Intentar mostrar el candidate si est√° disponible
                try:
                    from google.generativeai.types.generation_types import StopCandidateException
                    if isinstance(e, StopCandidateException):
                        with st.expander("üîç Ver detalles t√©cnicos del error"):
                            candidate = e.args[0] if e.args else None
                            if candidate:
                                st.write("**Candidate info:**")
                                st.write(f"- Finish reason: {candidate.finish_reason}")
                                st.write(f"- Safety ratings: {candidate.safety_ratings}")
                                if hasattr(candidate, 'content') and candidate.content:
                                    st.write("**Content parts:**")
                                    for i, part in enumerate(candidate.content.parts):
                                        st.write(f"Part {i}: {type(part).__name__}")
                                        if hasattr(part, 'function_call'):
                                            st.json({
                                                "function_name": part.function_call.name if hasattr(part.function_call, 'name') else "N/A",
                                                "args_raw": str(part.function_call.args) if hasattr(part.function_call, 'args') else "N/A"
                                            })
                except Exception as debug_error:
                    st.caption(f"No se pudo extraer informaci√≥n adicional: {debug_error}")

            # Informaci√≥n adicional de debug
            import traceback
            with st.expander("üìã Stack trace completo"):
                st.code(traceback.format_exc())

# Verificar si hay un mensaje pendiente de procesar (de acciones r√°pidas)
if st.session_state.pending_message:
    # Obtener el √∫ltimo mensaje del usuario
    if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
        prompt = st.session_state.messages[-1]["content"]
        process_user_message(prompt)
        st.session_state.pending_message = False

# Input del usuario
if prompt := st.chat_input("Escribe tu mensaje al coach..."):
    # A√±adir mensaje del usuario
    st.session_state.messages.append({"role": "user", "content": prompt})
    save_chat_to_db("user", prompt)

    # Mostrar mensaje del usuario
    with st.chat_message("user"):
        st.markdown(prompt)

    # Procesar el mensaje
    process_user_message(prompt)

# Botones de acci√≥n r√°pida
st.divider()
st.markdown("### üí° Acciones R√°pidas")

col1, col2, col3 = st.columns(3)

with col1:
    if st.button("üìä Ver mis √∫ltimas actividades"):
        quick_prompt = "Mu√©strame un resumen de mis √∫ltimos 7 d√≠as de entrenamiento"
        st.session_state.messages.append({"role": "user", "content": quick_prompt})
        save_chat_to_db("user", quick_prompt)
        st.session_state.pending_message = True
        st.rerun()

with col2:
    if st.button("üìÖ Planificar pr√≥xima semana"):
        quick_prompt = "Necesito que me propongas un plan de entrenamientos para la pr√≥xima semana. Primero revisa mis √∫ltimos entrenos y preg√∫ntame por mis sensaciones."
        st.session_state.messages.append({"role": "user", "content": quick_prompt})
        save_chat_to_db("user", quick_prompt)
        st.session_state.pending_message = True
        st.rerun()

with col3:
    if st.button("üéØ Ver plan actual"):
        quick_prompt = "¬øCu√°l es mi plan de entrenamiento actual? ¬øC√≥mo voy?"
        st.session_state.messages.append({"role": "user", "content": quick_prompt})
        save_chat_to_db("user", quick_prompt)
        st.session_state.pending_message = True
        st.rerun()

# Informaci√≥n adicional
with st.expander("‚ÑπÔ∏è C√≥mo usar el Coach IA"):
    st.markdown("""
    **Consejos para interactuar con tu coach:**

    1. **S√© espec√≠fico**: Cu√©ntale tus objetivos, sensaciones y dudas
    2. **Comparte feedback**: Despu√©s de cada entreno, cu√©ntale c√≥mo te sentiste
    3. **Pregunta libremente**: El coach tiene acceso a todos tus datos de Strava
    4. **Planificaci√≥n semanal**: P√≠dele que revise tu semana antes de planificar la siguiente

    **Ejemplos de preguntas:**
    - "¬øC√≥mo ha sido mi progreso en las √∫ltimas 4 semanas?"
    - "Hoy hice 10km y me sent√≠ muy cansado, ¬øqu√© entreno me recomiendas para ma√±ana?"
    - "Quiero preparar una media marat√≥n en 3 meses, ¬øqu√© plan me sugieres?"
    - "Mu√©strame los detalles de mi √∫ltimo entreno de series"
    """)
